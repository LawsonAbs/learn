{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 4 5 5 6 6 6]\n",
      "[1 1 1 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "import cleanlab\n",
    "import numpy as np\n",
    "# a = np.arange(10)\n",
    "a = np.array([1,2,3,4,4,5,5,6,6,6])\n",
    "print(a)\n",
    "res = cleanlab.util.value_counts(a)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [\"cat\",\"lion\",\"dog\",\"dog\"]\n",
    "res = cleanlab.util.value_counts(b)\n",
    "print(res) # [1 2 1]\n",
    "# 为什么这里得到的结果是 [1 2 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lawson/anaconda3/lib/python3.8/site-packages/cleanlab/util.py:439: UserWarning: \n",
      "        pyTorch supports Python version 2.7, 3.5, 3.6, 3.7.\n",
      "        cleanlab supports Python versions 2.7, 3.4, 3.5, 3.6.\n",
      "        You are using Python version 3.8.\n",
      "        You'll need to use a version compatible with both.\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca491dd5fa14c0ebc8f2fb2e421093b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77568d10d9204fe1981bcc190ce2d81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d434f68f0924695b7f668c37649958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005718b153964992992514860441d835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Author: LawsonAbs\n",
    "Date: 2020-09-15 20:42:38\n",
    "LastEditTime: 2020-10-21 19:59:05\n",
    "FilePath: /cleanlab/examples/mnist/label_errors_mnist_test_cnn.py\n",
    "我对这个文件进行一个简单的注释，便于理解，如果想看看这篇代码的详细讲解，可以在我的csdn中查看。\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "# sys.path.append(r'~/program/cleanlab/models')  我本想使用这个包中的文件的，而不是使用pip 安装好的cleanlab\n",
    "import os\n",
    "import traceback\n",
    "from datetime import datetime as dt\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# Important! Make fonts Type I fonts (necessary for publishing in ICML and other conference)\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "from torchvision import datasets\n",
    "\n",
    "# 使用cleanlab 的导入也就两个\n",
    "# 使用之前需要 安装cleanlab的包或者将本目录作为一个 搜索路径\n",
    "from cleanlab.models.mnist_pytorch import CNN, MNIST_TEST_SIZE, MNIST_TRAIN_SIZE\n",
    "import cleanlab\n",
    "\n",
    "\n",
    "X_train = np.arange(MNIST_TRAIN_SIZE)  # 得到一个数组\n",
    "X_test = np.arange(MNIST_TEST_SIZE)\n",
    "\n",
    "# 这里添加了download=True 参数，用于下载训练数据\n",
    "# y_train 中数据的样式 array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4]) \n",
    "y_train = datasets.MNIST('../data', train=True,download=True).train_labels.numpy()\n",
    "y_test = datasets.MNIST('../data', train=False,download=True).test_labels.numpy()\n",
    "\n",
    "\n",
    "# 存在疑问\n",
    "py_train = cleanlab.util.value_counts(y_train) / float(len(y_train))\n",
    "X_test_data = datasets.MNIST('../data', train=False,download=True).test_data.numpy()\n",
    "\n",
    "\n",
    "## Finding label errors in MNIST test set\n",
    "red_box_idxs = [947,5937,3520, 4163, 2597,9729, 4874, 3776] # 2130, 9642,449, 659]\n",
    "\n",
    "def imshow(inp, img_labels=None, img_pred=None,\n",
    "           img_fns = None, figsize=(10,10),\n",
    "           normalize=False, red_boxes=True,\n",
    "           savefig = False):\n",
    "    \"\"\"\n",
    "    Imshow for Tensor.\n",
    "    \"\"\"\n",
    "    height, width = inp.shape[1:]\n",
    "    xbins = 8\n",
    "    ybins = int(np.ceil(len(img_labels)/xbins))\n",
    "    xbin_width = width // xbins\n",
    "    ybin_height = height // ybins\n",
    "\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "    ax = plt.figure(figsize=figsize).gca()\n",
    "    ax.imshow(inp)\n",
    "    pad_size = (8-len(img_pred)%8)%8\n",
    "    img_labels = img_labels + ['']*pad_size #padding\n",
    "    img_pred = img_pred + ['']*pad_size #padding\n",
    "    img_fns = img_fns + ['']*pad_size #padding\n",
    "        \n",
    "    num_red_boxes = 0\n",
    "    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):\n",
    "        prediction = img_pred[idx]\n",
    "        label = img_labels[idx]\n",
    "        img_fn = img_fns[idx]\n",
    "        image_index = int(img_fn[13:])\n",
    "        \n",
    "        plt.hlines([j*ybin_height - .5],\n",
    "                   xmin=i*xbin_width,\n",
    "                   xmax=i*xbin_width + xbin_width,\n",
    "                   color = 'lightgray',\n",
    "                   linewidth=2)\n",
    "        \n",
    "        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1\n",
    "        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)\n",
    "        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))\n",
    "        \n",
    "        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1\n",
    "        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)\n",
    "        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))\n",
    "        \n",
    "        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1\n",
    "        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)\n",
    "        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))\n",
    "        \n",
    "        if not red_boxes:\n",
    "            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'gray', linewidth=5)\n",
    "        \n",
    "        if red_boxes and image_index in red_box_idxs:\n",
    "            # Draw red bounding box\n",
    "            num_red_boxes += 1\n",
    "            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)\n",
    "            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)\n",
    "            \n",
    "        \n",
    "    if red_boxes:\n",
    "        print('Number of red boxes:', num_red_boxes)\n",
    "    plt.axis('off')\n",
    "    if savefig:\n",
    "        plt.savefig('figs/mnist_test_label_errors'+str(len(img_labels))+'.pdf', pad_inches=0.0, bbox_inches='tight')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "np.random.seed(43)\n",
    "max_images = 8\n",
    "savefig = False\n",
    "prune_method = 'prune_by_noise_rate'\n",
    "\n",
    "# Pre-train\n",
    "cnn = CNN(epochs=10, log_interval=100, loader='test')  # pre-train 就是会在下面这个地方开始训练\n",
    "cnn.fit(X_test, y_test, loader='test')  # pre-train (overfit, not out-of-sample) to entire dataset.\n",
    "\n",
    "# Out-of-sample cross-validated holdout predicted probabilities\n",
    "np.random.seed(4)\n",
    "cnn.epochs = 1  # Single epoch for cross-validation (already pre-trained)\n",
    "\n",
    "\n",
    "'''\n",
    "01.这里的 X_test,y_test  不是ndarray数组吗？为什么作为参数传进去了？\n",
    "02.下面这个 cnn 就是一个 clf，是函数中一个比较关键的参数\n",
    "'''\n",
    "jc, psx = cleanlab.latent_estimation.estimate_confident_joint_and_cv_pred_proba(X_test, y_test, cnn)\n",
    "est_py, est_nm, est_inv = cleanlab.latent_estimation.estimate_latent(jc, y_test)\n",
    "\n",
    "# algorithmic identification of label errors\n",
    "# est_inv 参数的作用？？\n",
    "noise_idx = cleanlab.pruning.get_noise_indices(y_test, psx, est_inv, prune_method=prune_method) \n",
    "print('Number of estimated errors in test set:', sum(noise_idx))\n",
    "\n",
    "# hand-picked digits from rankpruning alg's results\n",
    "noise_idx = np.asarray([i in red_box_idxs for i in range(len(y_test))])\n",
    "pred = np.argmax(psx, axis=1)\n",
    "\n",
    "ordered_noise_idx = np.argsort(np.asarray([psx[i][j] for i,j in enumerate(y_test)])[noise_idx])\n",
    "prob_given = np.asarray([psx[i][j] for i,j in enumerate(y_test)])[noise_idx][ordered_noise_idx][:max_images]\n",
    "prob_pred = np.asarray([psx[i][j] for i,j in enumerate(pred)])[noise_idx][ordered_noise_idx][:max_images]\n",
    "img_idx = np.arange(len(noise_idx))[noise_idx][ordered_noise_idx][:max_images]\n",
    "label4viz = y_test[noise_idx][ordered_noise_idx][:max_images]\n",
    "pred4viz = pred[noise_idx][ordered_noise_idx][:max_images]\n",
    "\n",
    "graphic = torchvision.utils.make_grid(torch.from_numpy(np.concatenate([X_test_data[img_idx][:, None]]*3, axis=1)))\n",
    "img_labels = [\"given: \"+str(label4viz[w])+\" | conf: \"+str(np.round(prob_given[w],3)) for w in range(len(label4viz))]\n",
    "img_pred = [\"convnet guess: \"+str(pred4viz[w])+\" | conf: \"+str(np.round(prob_pred[w],3)) for w in range(len(pred4viz))]\n",
    "img_fns = [\"train img #: \" + str(item) for item in img_idx]\n",
    "\n",
    "# Display image\n",
    "imshow(\n",
    "    graphic, \n",
    "    img_labels = img_labels,\n",
    "    img_pred = img_pred,\n",
    "    img_fns = img_fns,\n",
    "    figsize=(40,max_images/1.1),\n",
    "    red_boxes = False,\n",
    "    savefig = savefig,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "### Show that results generalize across epochs and seeds\n",
    "\n",
    "prune_method = 'prune_by_noise_rate'\n",
    "\n",
    "# max_images = 24\n",
    "for epochs, seed in [\n",
    "    (8,15),\n",
    "    (15,14),\n",
    "    (10,14),\n",
    "    (20,13),\n",
    "    (8,13),\n",
    "    (10,12),\n",
    "    (8,12),\n",
    "    (10,10),\n",
    "    (8,9),\n",
    "    (10,3),\n",
    "    (10,2),\n",
    "    (4,14),\n",
    "    (3,13),\n",
    "    (2,12),\n",
    "]:\n",
    "    # Pre-train\n",
    "    np.random.seed(43)\n",
    "    cnn = CNN(epochs=epochs, log_interval=None, loader='test') #pre-train\n",
    "    cnn.fit(X_test, y_test, loader='test') # pre-train (overfit, not out-of-sample) to entire dataset.\n",
    "\n",
    "    # Out-of-sample cross-validated holdout predicted probabilities\n",
    "    np.random.seed(seed)\n",
    "    cnn.epochs = 1 # Single epoch for cross-validation (already pre-trained)\n",
    "    jc, psx = cleanlab.latent_estimation.estimate_confident_joint_and_cv_pred_proba(X_test, y_test, cnn)\n",
    "    est_py, est_nm, est_inv = cleanlab.latent_estimation.estimate_latent(jc, y_test)\n",
    "    # algorithmic identification of label errors\n",
    "    noise_idx = cleanlab.pruning.get_noise_indices(y_test, psx, est_inv, prune_method=prune_method)\n",
    "    print('Number of estimated errors in training set:', sum(noise_idx))\n",
    "    noise_idx = cleanlab.pruning.get_noise_indices(y_test, psx, est_inv, prune_method=prune_method, num_to_remove_per_class=5)\n",
    "    pred = np.argmax(psx, axis=1)\n",
    "\n",
    "    for max_images in [8,16]:\n",
    "        # Prepare and display figure ordered by lowest predicted probability\n",
    "        if sum(noise_idx) >= max_images:\n",
    "            print(\"Epochs:\", epochs, \"| Random seed:\", seed)\n",
    "            ordered_noise_idx = np.argsort(np.asarray([psx[i][j] for i,j in enumerate(y_test)])[noise_idx])\n",
    "\n",
    "            prob_given = np.asarray([psx[i][j] for i,j in enumerate(y_test)])[noise_idx][ordered_noise_idx][:max_images]\n",
    "            prob_pred = np.asarray([psx[i][j] for i,j in enumerate(pred)])[noise_idx][ordered_noise_idx][:max_images]\n",
    "            img_idx = np.arange(len(noise_idx))[noise_idx][ordered_noise_idx][:max_images]\n",
    "            label4viz = y_test[noise_idx][ordered_noise_idx][:max_images]\n",
    "            pred4viz = pred[noise_idx][ordered_noise_idx][:max_images]\n",
    "\n",
    "            graphic = torchvision.utils.make_grid(torch.from_numpy(np.concatenate([X_test_data[img_idx][:, None]]*3, axis=1)))\n",
    "            # graphic = np.concatenate([graphic[:, None]]*3, axis=1)\n",
    "            img_labels = [\"given: \"+str(label4viz[w])+\" | conf: \"+str(np.round(prob_given[w],3)) for w in range(len(label4viz))]\n",
    "            img_pred = [\"argmax pred: \"+str(pred4viz[w])+\" | conf: \"+str(np.round(prob_pred[w],3)) for w in range(len(pred4viz))]\n",
    "            img_fns = [\"train img #: \" + str(item) for item in img_idx]\n",
    "\n",
    "            imshow(graphic, img_labels = img_labels, img_pred = img_pred, img_fns = img_fns, figsize=(40,max_images/1.1))\n",
    "            plt.show() \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
