{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '非', '处', '方', '药', '物', '（', '乙', '类', '）', '江', '西', '青', '峰', '药', '业', '有', '限', '公', '司', '每', '片', '含', '生', '药', '0', '.', '6', '克', '口', '服', '。', '一', '次', '3～4', '片', '，', '一', '日', '3', '次', '。', '补', '血', '活', '血', '，', '调', '经', '止', '痛', '。', '用', '于', '血', '虚', '引', '起', '的', '面', '色', '萎', '黄', '，', '眩', '晕', '心', '悸', '，', '月', '经', '不', '调', '，', '痛', '经', '密', '封', '，', '防', '潮', '。', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-chinese\")\n",
    "input_ids = [  101,  7478,  1905,  3175,  5790,  4289,  8020,   734,  5102,  8021,\n",
    "          3736,  6205,  7471,  2292,  5790,   689,  3300,  7361,  1062,  1385,\n",
    "          3680,  4275,  1419,  4495,  5790,   121,   119,   127,  1046,  1366,\n",
    "          3302,   511,   671,  3613, 12907,  4275,  8024,   671,  3189,   124,\n",
    "          3613,   511,  6133,  6117,  3833,  6117,  8024,  6444,  5307,  3632,\n",
    "          4578,   511,  4500,   754,  6117,  5994,  2471,  6629,  4638,  7481,\n",
    "          5682,  5848,  7942,  8024,  4700,  3238,  2552,  2654,  8024,  3299,\n",
    "          5307,   679,  6444,  8024,  4578,  5307,  2166,  2196,  8024,  7344,\n",
    "          4060,   511,   102]\n",
    "out = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "bert = BertModel.from_pretrained(\"/home/lawson/pretrain/bert-base-uncased/\")\n",
    "print(bert.config)  # 输出bert模型的配置信息，其实这个是文件 config.json 中的信息"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
