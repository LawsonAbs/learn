{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2])\n",
      "tensor(3.5426)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# shape = (2,3,5) 这里的5代表就是类别数\n",
    "inputs = torch.randn((2,3,5)).argmax(-1).float()\n",
    "# 取3个数，范围是[0,3)  \n",
    "# 需要注意，因为 input 的shape 是(3,5)，就表明只有5类，所以下面的类别只能是5，否则会报 “IndexError: Target 5 is out of bounds.” 错\n",
    "target = torch.randint(2,(1,2)).long().squeeze(0)\n",
    "print(inputs.size())\n",
    "print(target.size())\n",
    "output = loss(inputs, target)\n",
    "print(output)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3696, -0.7458, -2.1737, -0.2998,  1.1934],\n",
      "        [ 1.2696,  1.4323,  0.0261, -1.0563, -1.4283],\n",
      "        [ 1.1892,  0.4937,  0.8378, -1.1135,  0.6217]], requires_grad=True)\n",
      "tensor([3, 4, 1])\n",
      "tensor(2.5061, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3,5, requires_grad=True)\n",
    "# 取3个数，范围是[0,3)  \n",
    "# 需要注意，因为 input 的shape 是(3,5)，就表明只有5类，所以下面的类别只能是5，否则会报 “IndexError: Target 5 is out of bounds.” 错\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4800, -0.9973, -0.9890,  ..., -0.1273, -0.9741,  0.3405],\n",
      "         [-1.4510,  0.1163,  1.3347,  ...,  0.3739,  1.5169,  0.8588],\n",
      "         [ 0.0551,  0.0434, -1.0954,  ...,  1.4244,  1.1643, -0.3839]],\n",
      "\n",
      "        [[ 0.2614, -0.8848,  0.7785,  ...,  0.0994, -1.8214, -0.0811],\n",
      "         [-0.8494, -0.8123, -0.6885,  ..., -0.5106, -0.4326, -0.4668],\n",
      "         [-0.6775,  0.3795,  0.6280,  ..., -0.0837,  1.3275, -0.1549]],\n",
      "\n",
      "        [[ 1.7200, -1.1760, -0.9193,  ...,  1.5581, -2.5250,  0.1159],\n",
      "         [-0.6486, -1.3171,  0.6819,  ..., -0.0117, -0.8388,  0.1259],\n",
      "         [ 0.2618,  1.4195,  0.4371,  ..., -1.9741, -0.6699, -0.2849]],\n",
      "\n",
      "        [[-0.5918,  1.1609,  0.2255,  ..., -1.3303, -0.4281,  0.2173],\n",
      "         [-0.4401,  0.1191, -0.0951,  ..., -0.4025, -0.3857, -1.0756],\n",
      "         [-0.7421,  1.5235,  0.0779,  ...,  0.6446, -0.4954,  0.2942]]])\n",
      "tensor([[2, 0, 1,  ..., 0, 2, 2],\n",
      "        [2, 0, 2,  ..., 0, 1, 2],\n",
      "        [0, 2, 2,  ..., 0, 0, 1],\n",
      "        [2, 2, 1,  ..., 1, 1, 0]])\n",
      "----------------\n",
      "tensor([[[-1.4800, -1.4510,  0.0551],\n",
      "         [-0.9973,  0.1163,  0.0434],\n",
      "         [-0.9890,  1.3347, -1.0954],\n",
      "         ...,\n",
      "         [-0.1273,  0.3739,  1.4244],\n",
      "         [-0.9741,  1.5169,  1.1643],\n",
      "         [ 0.3405,  0.8588, -0.3839]],\n",
      "\n",
      "        [[ 0.2614, -0.8494, -0.6775],\n",
      "         [-0.8848, -0.8123,  0.3795],\n",
      "         [ 0.7785, -0.6885,  0.6280],\n",
      "         ...,\n",
      "         [ 0.0994, -0.5106, -0.0837],\n",
      "         [-1.8214, -0.4326,  1.3275],\n",
      "         [-0.0811, -0.4668, -0.1549]],\n",
      "\n",
      "        [[ 1.7200, -0.6486,  0.2618],\n",
      "         [-1.1760, -1.3171,  1.4195],\n",
      "         [-0.9193,  0.6819,  0.4371],\n",
      "         ...,\n",
      "         [ 1.5581, -0.0117, -1.9741],\n",
      "         [-2.5250, -0.8388, -0.6699],\n",
      "         [ 0.1159,  0.1259, -0.2849]],\n",
      "\n",
      "        [[-0.5918, -0.4401, -0.7421],\n",
      "         [ 1.1609,  0.1191,  1.5235],\n",
      "         [ 0.2255, -0.0951,  0.0779],\n",
      "         ...,\n",
      "         [-1.3303, -0.4025,  0.6446],\n",
      "         [-0.4281, -0.3857, -0.4954],\n",
      "         [ 0.2173, -1.0756,  0.2942]]])\n",
      "tensor(1.4066) tensor(1.4066)\n"
     ]
    }
   ],
   "source": [
    "'''CrossEntropyLoss()函数的使用\n",
    "'''\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "pred = t.randn(4,3,512)  # 4是batch，3是类别数, 512 是计算损失的维度。pred 代表预测的结果\n",
    "gold = t.randint(3,(4,512)) #范围是[0,3) ，也就是类别数；shape 是 (4,512) 。gold是标签\n",
    "loss = nn.CrossEntropyLoss() # 计算损失\n",
    "print(pred)\n",
    "print(gold)\n",
    "out1 = loss(pred,gold)\n",
    "\n",
    "# 下面是使用第二种方法计算损失\n",
    "# 思想是：先转换数据类型，然后再求解\n",
    "print(\"----------------\")\n",
    "pred =pred.permute(0,2,1)  # 调整结构。在使用 view() 的时候是不会改变内存中数据的顺序的，但是permute()是会的\n",
    "print(pred)\n",
    "out2 = loss(pred.reshape(4*512,3),gold.view(512*4))\n",
    "print(out1,out2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
