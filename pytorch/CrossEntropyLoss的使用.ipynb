{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "这个比较器结合 LogSoftmax 和 NLLLoss实现。\n",
    "当训练一个C类别分类问题时，它是非常有用的。如果提供了可选参数 weight（是一个一维的tensor），这将赋值给每个类别。在训练一个类别不均衡的数据集时，是非常有用的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3656)\n",
      "tensor(0.3136)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"构造不同的input，比较其损失大小\n",
    "01.查看标签平滑对计算损失得到的影响\n",
    "\"\"\"\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# 构造输入输出\n",
    "input_1=t.tensor([[0.9238,0.1],[0.1, 0.912]])\n",
    "input_2=t.tensor([[0.9999,0.001],[0.001, 0.9999]])\n",
    "\n",
    "target = t.tensor([0, 1]) # 必须使用long类型\n",
    "\n",
    "out_1 = loss(input_1, target)\n",
    "out_2 = loss(input_2, target)\n",
    "print(out_1) # 损失大\n",
    "print(out_2) # 损失小\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3567)\n",
      "tensor(0.5261)\n",
      "tensor(0.4414)\n"
     ]
    }
   ],
   "source": [
    "'''比较使用标签平滑与否得到的损失比较\n",
    "02.\n",
    "01.可以发现使用label_smooth 得到的损失较大\n",
    "\n",
    "'''\n",
    "bce = nn.BCELoss()\n",
    "label = t.tensor([0.,1.])\n",
    "label_smooth_1 = t.tensor([0.2,0.8]) # 使用一个标签平滑\n",
    "label_smooth_2 = t.tensor([0.1,0.9])\n",
    "pred = t.tensor([0.3,0.7])\n",
    "loss_3 = bce(pred,label)\n",
    "loss_4 = bce(pred,label_smooth_1)\n",
    "loss_5 = bce(pred,label_smooth_2)\n",
    "\n",
    "print(loss_3)\n",
    "print(loss_4)\n",
    "print(loss_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7308, 0.2692],\n",
      "        [0.2692, 0.7308]])\n",
      "tensor([0.7308, 0.7308])\n",
      "tensor(0.8130)\n"
     ]
    }
   ],
   "source": [
    "inp =t.tensor([[0.9999,0.001],[0.001, 0.9999]])\n",
    "loss_fct = nn.BCELoss() # 计算交叉熵损失\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "x = softmax(inp)\n",
    "print(x)\n",
    "xx_val,xx_idx = x.max(dim=-1)\n",
    "print(xx_val)\n",
    "y = t.tensor([0, 1]).float()\n",
    "\n",
    "loss = loss_fct(xx_val,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5651,  0.2735,  0.2883,  0.7495,  0.4461],\n",
      "        [-0.4567,  0.9265,  0.8855,  0.5502,  1.2194],\n",
      "        [ 1.4972, -1.1494,  0.6773, -0.2750, -0.0401]], requires_grad=True)\n",
      "torch.Size([3, 5])\n",
      "-------------------------\n",
      "tensor([1, 2, 1])\n",
      "torch.Size([3])\n",
      "torch.Size([])\n",
      "tensor(2.1429, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# 如果在构造器中添加了 reduction = \"none\" 参数，则不再返回一个 scalar，也无法反向更新\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3,5, requires_grad=True)\n",
    "\n",
    "# 取3个数\n",
    "# 需要注意，因为 input 的shape 是(3,5)，就表明只有5类，所以下面的类别只能是0-4，否则会报 “IndexError: Target 5 is out of bounds.” 错\n",
    "# random_() 中的数的含义应该是指定一个到其范围内的数，这里就是生成大小为[0,5) 的整数\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input)\n",
    "print(input.size())\n",
    "print(\"-------------------------\")\n",
    "print(target)\n",
    "print(target.size())\n",
    "output = loss(input, target)\n",
    "print(output.size())\n",
    "output.backward() \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3是类别数, 5 是计算损失的维度\n"
     ]
    }
   ],
   "source": [
    "def get_rid_of_number_in_str(string):\n",
    "    deleted = [1] * len(string)\n",
    "    res = \"\" \n",
    "    pre_char = '' # 上一个字符\n",
    "    for i,char in enumerate(string):\n",
    "        if char.isdigit()  and pre_char.isdigit():# 如果当前是数字，且之前也是数字\n",
    "            deleted[i] = 0 # 记为待删除\n",
    "        #print(char,end='')\n",
    "        pre_char = char\n",
    "    \n",
    "    for i in range(len(string)):\n",
    "        if deleted[i]:\n",
    "            res+=string[i]\n",
    "    return res\n",
    "res = get_rid_of_number_in_str(\"3是类别数, 512 是计算损失的维度\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a='1'\n",
    "print(a.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2437, -0.3002, -1.8958, -0.8022, -1.1080],\n",
      "         [-0.2849, -1.3770,  1.6620, -1.4426, -0.7600],\n",
      "         [ 0.1275,  1.4556, -0.4783, -0.6048, -1.0159]],\n",
      "\n",
      "        [[ 0.0476,  1.3372,  0.1179,  0.5213,  0.1213],\n",
      "         [ 1.5183,  0.1490,  1.3848, -0.3382,  1.5580],\n",
      "         [ 1.5705, -0.2842, -0.5677, -0.6010,  1.0007]],\n",
      "\n",
      "        [[-0.0250, -0.9253,  0.0980, -0.0689, -0.3566],\n",
      "         [-0.0494,  0.4148, -0.3458,  0.3093, -1.1003],\n",
      "         [-1.2310,  0.7205,  0.9149,  1.2588, -0.2963]],\n",
      "\n",
      "        [[ 0.0666, -0.4448, -0.3556, -0.6903,  0.1265],\n",
      "         [ 0.9052,  1.0447,  0.4522, -0.7184,  0.2013],\n",
      "         [-0.9177,  1.4244,  1.9818,  0.7684, -1.7831]]])\n",
      "tensor([[0, 1, 0, 1, 0],\n",
      "        [1, 2, 0, 2, 2],\n",
      "        [2, 0, 2, 0, 1],\n",
      "        [2, 2, 1, 0, 1]])\n",
      "----------------\n",
      "tensor([[[ 0.2437, -0.2849,  0.1275],\n",
      "         [-0.3002, -1.3770,  1.4556],\n",
      "         [-1.8958,  1.6620, -0.4783],\n",
      "         [-0.8022, -1.4426, -0.6048],\n",
      "         [-1.1080, -0.7600, -1.0159]],\n",
      "\n",
      "        [[ 0.0476,  1.5183,  1.5705],\n",
      "         [ 1.3372,  0.1490, -0.2842],\n",
      "         [ 0.1179,  1.3848, -0.5677],\n",
      "         [ 0.5213, -0.3382, -0.6010],\n",
      "         [ 0.1213,  1.5580,  1.0007]],\n",
      "\n",
      "        [[-0.0250, -0.0494, -1.2310],\n",
      "         [-0.9253,  0.4148,  0.7205],\n",
      "         [ 0.0980, -0.3458,  0.9149],\n",
      "         [-0.0689,  0.3093,  1.2588],\n",
      "         [-0.3566, -1.1003, -0.2963]],\n",
      "\n",
      "        [[ 0.0666,  0.9052, -0.9177],\n",
      "         [-0.4448,  1.0447,  1.4244],\n",
      "         [-0.3556,  0.4522,  1.9818],\n",
      "         [-0.6903, -0.7184,  0.7684],\n",
      "         [ 0.1265,  0.2013, -1.7831]]])\n",
      "tensor(1.6750) tensor(1.6750)\n"
     ]
    }
   ],
   "source": [
    "'''CrossEntropyLoss()函数的使用\n",
    "'''\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "# 生成的size 是(4,3,5)。\n",
    "# 对应到预测就是 4是batch，3是类别数, 5 是计算损失的维度。pred 代表预测的结果\n",
    "pred = t.randn(4,3,5)  \n",
    "gold = t.randint(3,(4,5)) # 范围是[0,3) ，也就是类别数；shape 是 (4,5) 。gold是标签\n",
    "loss = nn.CrossEntropyLoss() # 计算损失\n",
    "print(pred)\n",
    "print(gold)\n",
    "out1 = loss(pred,gold)\n",
    "\n",
    "# 下面是使用第二种方法计算损失\n",
    "# 思想是：先转换数据类型，然后再求解\n",
    "print(\"----------------\")\n",
    "pred =pred.permute(0,2,1)  # 调整结构。在使用 view() 的时候是不会改变内存中数据的顺序的，但是permute()是会的\n",
    "print(pred)\n",
    "out2 = loss(pred.reshape(4*5,3),gold.view(5*4))\n",
    "print(out1,out2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
