{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+---------+\n",
      "| raw_words                    | words                        | seq_len |\n",
      "+------------------------------+------------------------------+---------+\n",
      "| This is the first instanc... | ['this', 'is', 'the', 'fi... | 6       |\n",
      "| Second instance .            | ['Second', 'instance', '.... | 3       |\n",
      "| Third instance .             | ['Third', 'instance', '.'... | 3       |\n",
      "+------------------------------+------------------------------+---------+\n",
      "<class 'fastNLP.core.dataset.DataSet'>\n",
      "3\n",
      "+------------------------------+------------------------------+---------+\n",
      "| raw_words                    | words                        | seq_len |\n",
      "+------------------------------+------------------------------+---------+\n",
      "| This is the first instanc... | ['this', 'is', 'the', 'fi... | 6       |\n",
      "+------------------------------+------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "from fastNLP import DataSet\n",
    "data = {'raw_words':[\"This is the first instance .\", \"Second instance .\", \"Third instance .\"],  # value 长度为3的list\n",
    "        'words': [['this', 'is', 'the', 'first', 'instance', '.'], ['Second', 'instance', '.'], ['Third', 'instance', '.']],  # value 为长度为3 的list\n",
    "        'seq_len': [6, 3, 3] # value（也就是[6,3,3]） 为长度为3的 list\n",
    "       } \n",
    "\n",
    "# 构造DataSet实例的方法 =》 直接传入一个dict \n",
    "# 键值具体的内容可随意\n",
    "# 传入的dict的每个key的value应该为具有相同长度的list\n",
    "dataset = DataSet(data)\n",
    "\n",
    "print(dataset)\n",
    "print(type(dataset)) # <class 'fastNLP.core.dataset.DataSet'>\n",
    "print(len(dataset)) # 3\n",
    "for i in range(len(dataset)-1,0,-1):\n",
    "    dataset.delete_instance(i)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+---------+\n",
      "| raw_words                    | words                        | seq_len |\n",
      "+------------------------------+------------------------------+---------+\n",
      "| This is the first instanc... | ['this', 'is', 'the', 'fi... | 6       |\n",
      "+------------------------------+------------------------------+---------+\n",
      "+-------------------+------------------------------+---------+\n",
      "| raw_words         | words                        | seq_len |\n",
      "+-------------------+------------------------------+---------+\n",
      "| Second instance . | ['Second', 'instance', '.... | 3       |\n",
      "+-------------------+------------------------------+---------+\n",
      "+------------------+------------------------------+---------+\n",
      "| raw_words        | words                        | seq_len |\n",
      "+------------------+------------------------------+---------+\n",
      "| Third instance . | ['Third', 'instance', '.'... | 3       |\n",
      "+------------------+------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "for instance in dataset:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "| a  | c |\n",
      "+----+---+\n",
      "| -5 | 0 |\n",
      "| -4 | 0 |\n",
      "| -3 | 0 |\n",
      "| -2 | 0 |\n",
      "| -1 | 0 |\n",
      "| 0  | 0 |\n",
      "| 1  | 0 |\n",
      "| 2  | 0 |\n",
      "| 3  | 0 |\n",
      "| 4  | 0 |\n",
      "+----+---+\n"
     ]
    }
   ],
   "source": [
    "from fastNLP import DataSet\n",
    "dataset = DataSet({'a': range(-5, 5), 'c': [0]*10})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "| raw_words                    | len |\n",
      "+------------------------------+-----+\n",
      "| This is the first instance . | 5   |\n",
      "| Second instance .            | 2   |\n",
      "| Third instance .             | 2   |\n",
      "+------------------------------+-----+\n",
      "+------------------------------+\n",
      "| raw_words                    |\n",
      "+------------------------------+\n",
      "| This is the first instance . |\n",
      "| Second instance .            |\n",
      "| Third instance .             |\n",
      "+------------------------------+\n",
      "+------------------------------+\n",
      "| raw_words                    |\n",
      "+------------------------------+\n",
      "| This is the first instance . |\n",
      "| Third instance .             |\n",
      "+------------------------------+\n"
     ]
    }
   ],
   "source": [
    "'''使用delete方法删除instance 和 field\n",
    "'''\n",
    "from fastNLP import DataSet\n",
    "dataset = DataSet({'raw_words':[\"This is the first instance .\", \"Second instance .\", \"Third instance .\"],\n",
    "                  'len':[5,2,2]})\n",
    "print(dataset)\n",
    "# 删除voca field\n",
    "dataset.delete_field(\"len\")\n",
    "print(dataset)\n",
    "\n",
    "# 删除第2行，下标从0开始\n",
    "dataset.delete_instance(1) \n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "| raw_words                    |\n",
      "+------------------------------+\n",
      "| This is the first instance . |\n",
      "| Second instance .            |\n",
      "| Third instance .             |\n",
      "+------------------------------+\n",
      "+------------------------------+------------------------------------------+\n",
      "| raw_words                    | words                                    |\n",
      "+------------------------------+------------------------------------------+\n",
      "| This is the first instance . | ['This', 'is', 'the', 'first', 'insta... |\n",
      "| Second instance .            | ['Second', 'instance', '.']              |\n",
      "| Third instance .             | ['Third', 'instance', '.']               |\n",
      "+------------------------------+------------------------------------------+\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "| raw_words                    | words                        | voca                         |\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "| This is the first instanc... | ['This', 'is', 'the', 'fi... | ['This', 'is', 'the', 'fi... |\n",
      "| Second instance .            | ['Second', 'instance', '.... | ['Second', 'instance', '.... |\n",
      "| Third instance .             | ['Third', 'instance', '.'... | ['Third', 'instance', '.'... |\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "| raw_words                    | words                        | voca                         |\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "| This is the first instanc... | ['This', 'is', 'the', 'fi... | ['This', 'is', 'the', 'fi... |\n",
      "| Second instance .            | ['Second', 'instance', '.... | ['Second', 'instance', '.... |\n",
      "| Third instance .             | ['Third', 'instance', '.'... | ['Third', 'instance', '.'... |\n",
      "+------------------------------+------------------------------+------------------------------+\n"
     ]
    }
   ],
   "source": [
    "'''使用apply() 或 apply_field()方法处理文本\n",
    "'''\n",
    "from fastNLP import DataSet\n",
    "data = {'raw_words':[\"This is the first instance .\", \"Second instance .\", \"Third instance .\"]}\n",
    "dataset = DataSet(data)\n",
    "\n",
    "print(dataset)\n",
    "# 将句子分成单词形式, 详见DataSet.apply()方法\n",
    "# 用 new_field_name 参数指定函数返回值组成的新 field 的名称\n",
    "# 原地修改\n",
    "dataset.apply(lambda ins: ins['raw_words'].split(), new_field_name='words')\n",
    "print(dataset)\n",
    "\n",
    "# 或使用DataSet.apply_field()\n",
    "# 原地修改\n",
    "dataset.apply_field(lambda sent:sent.split(), field_name='raw_words', new_field_name='voca')\n",
    "print(dataset)\n",
    "\n",
    "# 除了匿名函数，也可以定义函数传递进去\n",
    "def get_words(instance):\n",
    "    sentence = instance['raw_words']\n",
    "    words = sentence.split()\n",
    "    return words\n",
    "dataset.apply(get_words, new_field_name='words')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "| raw_words                    | len |\n",
      "+------------------------------+-----+\n",
      "| This is the first instance . | 5   |\n",
      "| Second instance .            | 3   |\n",
      "| Third instance .             | 3   |\n",
      "+------------------------------+-----+\n",
      "+------------------------------+-----+-----------+\n",
      "| raw_words                    | len | after_len |\n",
      "+------------------------------+-----+-----------+\n",
      "| This is the first instanc... | 5   | 6         |\n",
      "| Second instance .            | 3   | 4         |\n",
      "| Third instance .             | 3   | 4         |\n",
      "+------------------------------+-----+-----------+\n"
     ]
    }
   ],
   "source": [
    "'''使用apply_field()方法\n",
    "'''\n",
    "from fastNLP import DataSet\n",
    "data = {'raw_words':[\"This is the first instance .\", \"Second instance .\", \"Third instance .\"],\n",
    "       'len':[5,3,3]}\n",
    "dataset = DataSet(data)\n",
    "print(dataset)\n",
    "dataset.apply_field(lambda x:x+1, 'len','after_len')\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "| raw_words                    |\n",
      "+------------------------------+\n",
      "| This is the first instance . |\n",
      "| Second instance .            |\n",
      "| Third instance .             |\n",
      "+------------------------------+\n",
      "['raw_words']\n",
      "This is the first instance .\n",
      "Second instance .\n",
      "Third instance .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''获取某个field 的操作\n",
    "'''\n",
    "from fastNLP import DataSet\n",
    "data = {'raw_words':[\"This is the first instance .\", \"Second instance .\", \"Third instance .\"]}\n",
    "dataset = DataSet(data)\n",
    "print(dataset)\n",
    "\n",
    "# 获取数据集中所有的field名，也就是所有的列名\n",
    "fields = dataset.get_field_names()\n",
    "print(fields)\n",
    "\n",
    "# 获取field 下所有的值，返回结果是个fieldArray，可遍历输出\n",
    "out = dataset.get_field('raw_words')\n",
    "for i in out: \n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
